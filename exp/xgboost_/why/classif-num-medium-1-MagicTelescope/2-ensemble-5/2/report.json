{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.xgboost_.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9997860504920839,
                "recall": 1.0,
                "f1-score": 0.9998930138012196,
                "support": 4673
            },
            "1": {
                "precision": 1.0,
                "recall": 0.9997867803837953,
                "f1-score": 0.9998933788250347,
                "support": 4690
            },
            "accuracy": 0.9998931966250133,
            "macro avg": {
                "precision": 0.999893025246042,
                "recall": 0.9998933901918976,
                "f1-score": 0.9998931963131272,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.9998932194755429,
                "recall": 0.9998931966250133,
                "f1-score": 0.9998931966445063,
                "support": 9363
            },
            "cross-entropy": 0.0624954966973387,
            "roc-auc": 1.0,
            "score": 0.9998931966250133
        },
        "val": {
            "0": {
                "precision": 0.8659305993690851,
                "recall": 0.8812199036918138,
                "f1-score": 0.873508353221957,
                "support": 623
            },
            "1": {
                "precision": 0.8699472759226714,
                "recall": 0.853448275862069,
                "f1-score": 0.8616187989556137,
                "support": 580
            },
            "accuracy": 0.8678304239401496,
            "macro avg": {
                "precision": 0.8679389376458783,
                "recall": 0.8673340897769414,
                "f1-score": 0.8675635760887853,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8678671516559346,
                "recall": 0.8678304239401496,
                "f1-score": 0.8677760660445014,
                "support": 1203
            },
            "cross-entropy": 0.3273723636431732,
            "roc-auc": 0.9359688935628494,
            "score": 0.8678304239401496
        },
        "test": {
            "0": {
                "precision": 0.8457912457912458,
                "recall": 0.9022988505747126,
                "f1-score": 0.873131734445603,
                "support": 1392
            },
            "1": {
                "precision": 0.8973584905660378,
                "recall": 0.8385049365303244,
                "f1-score": 0.8669340138534452,
                "support": 1418
            },
            "accuracy": 0.8701067615658363,
            "macro avg": {
                "precision": 0.8715748681786417,
                "recall": 0.8704018935525185,
                "f1-score": 0.870032874149524,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8718134355032228,
                "recall": 0.8701067615658363,
                "f1-score": 0.8700042014208058,
                "support": 2810
            },
            "cross-entropy": 0.3082338221210803,
            "roc-auc": 0.9412150633075564,
            "score": 0.8701067615658363
        }
    }
}
