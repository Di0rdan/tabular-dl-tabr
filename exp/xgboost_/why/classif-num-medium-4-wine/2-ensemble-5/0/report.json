{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.xgboost_.main",
    "data": ":data/classif-num-medium-4-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 0.9988876529477196,
                "f1-score": 0.9994435169727323,
                "support": 899
            },
            "1": {
                "precision": 0.9988751406074241,
                "recall": 1.0,
                "f1-score": 0.9994372537985369,
                "support": 888
            },
            "accuracy": 0.9994404029099049,
            "macro avg": {
                "precision": 0.999437570303712,
                "recall": 0.9994438264738599,
                "f1-score": 0.9994403853856346,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9994410323779477,
                "recall": 0.9994404029099049,
                "f1-score": 0.999440404662332,
                "support": 1787
            },
            "cross-entropy": 0.5675366769546661,
            "roc-auc": 0.9999999999999999,
            "score": 0.9994404029099049
        },
        "val": {
            "0": {
                "precision": 0.8878504672897196,
                "recall": 0.7851239669421488,
                "f1-score": 0.8333333333333334,
                "support": 121
            },
            "1": {
                "precision": 0.7886178861788617,
                "recall": 0.8899082568807339,
                "f1-score": 0.8362068965517241,
                "support": 109
            },
            "accuracy": 0.8347826086956521,
            "macro avg": {
                "precision": 0.8382341767342907,
                "recall": 0.8375161119114414,
                "f1-score": 0.8347701149425287,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8408228527632695,
                "recall": 0.8347826086956521,
                "f1-score": 0.8346951524237882,
                "support": 230
            },
            "cross-entropy": 0.625807574552682,
            "roc-auc": 0.9010539085601639,
            "score": 0.8347826086956521
        },
        "test": {
            "0": {
                "precision": 0.8264462809917356,
                "recall": 0.7782101167315175,
                "f1-score": 0.8016032064128256,
                "support": 257
            },
            "1": {
                "precision": 0.8067796610169492,
                "recall": 0.85,
                "f1-score": 0.8278260869565218,
                "support": 280
            },
            "accuracy": 0.8156424581005587,
            "macro avg": {
                "precision": 0.8166129710043424,
                "recall": 0.8141050583657587,
                "f1-score": 0.8147146466846737,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.8161918050272288,
                "recall": 0.8156424581005587,
                "f1-score": 0.815276216752183,
                "support": 537
            },
            "cross-entropy": 0.6303328166828842,
            "roc-auc": 0.8885352973874375,
            "score": 0.8156424581005587
        }
    }
}
