{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.xgboost_.main",
    "data": ":data/classif-num-medium-2-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8872043662825955,
                "recall": 0.9406343763394771,
                "f1-score": 0.9131384583376677,
                "support": 4666
            },
            "1": {
                "precision": 0.9372735507246377,
                "recall": 0.8812007664466681,
                "f1-score": 0.9083726544496873,
                "support": 4697
            },
            "accuracy": 0.9108191818861476,
            "macro avg": {
                "precision": 0.9122389585036166,
                "recall": 0.9109175713930726,
                "f1-score": 0.9107555563936776,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.9123218456507759,
                "recall": 0.9108191818861476,
                "f1-score": 0.9107476668326112,
                "support": 9363
            },
            "cross-entropy": 0.23200188432287014,
            "roc-auc": 0.9711496544884921,
            "score": 0.9108191818861476
        },
        "val": {
            "0": {
                "precision": 0.8550488599348535,
                "recall": 0.875,
                "f1-score": 0.8649093904448105,
                "support": 600
            },
            "1": {
                "precision": 0.8726655348047538,
                "recall": 0.8524046434494196,
                "f1-score": 0.8624161073825505,
                "support": 603
            },
            "accuracy": 0.8636741479634248,
            "macro avg": {
                "precision": 0.8638571973698037,
                "recall": 0.8637023217247097,
                "f1-score": 0.8636627489136806,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8638791632985692,
                "recall": 0.8636741479634248,
                "f1-score": 0.863659640081932,
                "support": 1203
            },
            "cross-entropy": 0.3350896247285495,
            "roc-auc": 0.9292509673852958,
            "score": 0.8636741479634248
        },
        "test": {
            "0": {
                "precision": 0.8399209486166008,
                "recall": 0.8966244725738397,
                "f1-score": 0.8673469387755102,
                "support": 1422
            },
            "1": {
                "precision": 0.8862229102167183,
                "recall": 0.8249279538904899,
                "f1-score": 0.8544776119402985,
                "support": 1388
            },
            "accuracy": 0.8612099644128114,
            "macro avg": {
                "precision": 0.8630719294166596,
                "recall": 0.8607762132321648,
                "f1-score": 0.8609122753579044,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.862791810787762,
                "recall": 0.8612099644128114,
                "f1-score": 0.8609901324953415,
                "support": 2810
            },
            "cross-entropy": 0.322293642629433,
            "roc-auc": 0.9334470263500286,
            "score": 0.8612099644128114
        }
    }
}
