seed = 3
batch_size = 256
patience = 16
n_epochs = inf
context_size = 96

[data]
seed = 0
cache = true
path = ":data/regression-num-medium-0-superconduct"
num_policy = "quantile"
cat_policy = "__null__"
y_policy = "standard"

[model]
d_main = 376
context_dropout = 0.1861073608674267
d_multiplier = 2.0
encoder_n_blocks = 1
predictor_n_blocks = 2
mixer_normalization = "auto"
dropout0 = 0.3952836403489469
dropout1 = 0.0
normalization = "LayerNorm"
activation = "ReLU"

[model.num_embeddings]
type = "PLREmbeddings"
n_frequencies = 91
frequency_scale = 1.2281201962993546
d_embedding = 58
lite = true

[optimizer]
type = "AdamW"
lr = 9.429298812029297e-05
weight_decay = 2.432935386632459e-06
