{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-0-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8713147410358566,
                "recall": 0.927874416631311,
                "f1-score": 0.8987055681117733,
                "support": 4714
            },
            "1": {
                "precision": 0.9217131015427125,
                "recall": 0.8610453861045386,
                "f1-score": 0.890346975088968,
                "support": 4649
            },
            "accuracy": 0.8946918722631635,
            "macro avg": {
                "precision": 0.8965139212892845,
                "recall": 0.8944599013679249,
                "f1-score": 0.8945262716003706,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8963389830519167,
                "recall": 0.8946918722631635,
                "f1-score": 0.8945552851935823,
                "support": 9363
            },
            "cross-entropy": 0.2473142751870103,
            "roc-auc": 0.9613401744327021,
            "score": 0.8946918722631635
        },
        "val": {
            "0": {
                "precision": 0.8470209339774557,
                "recall": 0.9053356282271945,
                "f1-score": 0.8752079866888519,
                "support": 581
            },
            "1": {
                "precision": 0.9054982817869416,
                "recall": 0.8472668810289389,
                "f1-score": 0.8754152823920266,
                "support": 622
            },
            "accuracy": 0.8753117206982544,
            "macro avg": {
                "precision": 0.8762596078821987,
                "recall": 0.8763012546280666,
                "f1-score": 0.8753116345404393,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8772561046653196,
                "recall": 0.8753117206982544,
                "f1-score": 0.8753151670108591,
                "support": 1203
            },
            "cross-entropy": 0.2983943694993515,
            "roc-auc": 0.9435832443231815,
            "score": 0.8753117206982544
        },
        "test": {
            "0": {
                "precision": 0.8348745046235139,
                "recall": 0.9073941134242641,
                "f1-score": 0.869625042999656,
                "support": 1393
            },
            "1": {
                "precision": 0.9004629629629629,
                "recall": 0.8235709244883557,
                "f1-score": 0.8603022484334685,
                "support": 1417
            },
            "accuracy": 0.8651245551601423,
            "macro avg": {
                "precision": 0.8676687337932384,
                "recall": 0.8654825189563099,
                "f1-score": 0.8649636457165623,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8679488268537626,
                "recall": 0.8651245551601423,
                "f1-score": 0.864923833070728,
                "support": 2810
            },
            "cross-entropy": 0.32196576176848507,
            "roc-auc": 0.9354950982354052,
            "score": 0.8651245551601423
        }
    }
}