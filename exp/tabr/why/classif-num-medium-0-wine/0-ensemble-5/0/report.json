{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-0-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.881437125748503,
                "recall": 0.8214285714285714,
                "f1-score": 0.8503755054881571,
                "support": 896
            },
            "1": {
                "precision": 0.8319327731092437,
                "recall": 0.8888888888888888,
                "f1-score": 0.8594682582745523,
                "support": 891
            },
            "accuracy": 0.8550643536653609,
            "macro avg": {
                "precision": 0.8566849494288733,
                "recall": 0.8551587301587301,
                "f1-score": 0.8549218818813547,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.8567542056580832,
                "recall": 0.8550643536653609,
                "f1-score": 0.8549091611863543,
                "support": 1787
            },
            "cross-entropy": 0.3307895511448102,
            "roc-auc": 0.9389029180695847,
            "score": 0.8550643536653609
        },
        "val": {
            "0": {
                "precision": 0.8378378378378378,
                "recall": 0.8532110091743119,
                "f1-score": 0.8454545454545455,
                "support": 109
            },
            "1": {
                "precision": 0.865546218487395,
                "recall": 0.8512396694214877,
                "f1-score": 0.8583333333333334,
                "support": 121
            },
            "accuracy": 0.8521739130434782,
            "macro avg": {
                "precision": 0.8516920281626164,
                "recall": 0.8522253392978998,
                "f1-score": 0.8518939393939394,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8524148554839092,
                "recall": 0.8521739130434782,
                "f1-score": 0.852229907773386,
                "support": 230
            },
            "cross-entropy": 0.33877816519404175,
            "roc-auc": 0.9347941466373493,
            "score": 0.8521739130434782
        },
        "test": {
            "0": {
                "precision": 0.8442622950819673,
                "recall": 0.7573529411764706,
                "f1-score": 0.7984496124031008,
                "support": 272
            },
            "1": {
                "precision": 0.7747440273037542,
                "recall": 0.8566037735849057,
                "f1-score": 0.8136200716845877,
                "support": 265
            },
            "accuracy": 0.8063314711359404,
            "macro avg": {
                "precision": 0.8095031611928607,
                "recall": 0.8069783573806881,
                "f1-score": 0.8060348420438442,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.8099562597724208,
                "recall": 0.8063314711359404,
                "f1-score": 0.8059359656798122,
                "support": 537
            },
            "cross-entropy": 0.4045033301114628,
            "roc-auc": 0.89830743618202,
            "score": 0.8063314711359404
        }
    }
}