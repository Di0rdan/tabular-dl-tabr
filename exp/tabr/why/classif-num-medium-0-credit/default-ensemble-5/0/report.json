{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-0-credit",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7809633027522935,
                "recall": 0.8120031796502385,
                "f1-score": 0.7961808261886204,
                "support": 5032
            },
            "1": {
                "precision": 0.8015939597315436,
                "recall": 0.7693236714975845,
                "f1-score": 0.785127362366475,
                "support": 4968
            },
            "accuracy": 0.7908,
            "macro avg": {
                "precision": 0.7912786312419186,
                "recall": 0.7906634255739116,
                "f1-score": 0.7906540942775477,
                "support": 10000
            },
            "weighted avg": {
                "precision": 0.7912126131395849,
                "recall": 0.7908,
                "f1-score": 0.7906894653617785,
                "support": 10000
            },
            "cross-entropy": 0.45149972982904074,
            "roc-auc": 0.8694020707088161,
            "score": 0.7908
        },
        "val": {
            "0": {
                "precision": 0.7767083734359962,
                "recall": 0.813508064516129,
                "f1-score": 0.7946824224519942,
                "support": 992
            },
            "1": {
                "precision": 0.8102564102564103,
                "recall": 0.7729941291585127,
                "f1-score": 0.7911867801702555,
                "support": 1022
            },
            "accuracy": 0.7929493545183715,
            "macro avg": {
                "precision": 0.7934823918462033,
                "recall": 0.7932510968373209,
                "f1-score": 0.7929346013111248,
                "support": 2014
            },
            "weighted avg": {
                "precision": 0.7937322530936244,
                "recall": 0.7929493545183715,
                "f1-score": 0.792908566239513,
                "support": 2014
            },
            "cross-entropy": 0.4619996503925235,
            "roc-auc": 0.8632119578940723,
            "score": 0.7929493545183715
        },
        "test": {
            "0": {
                "precision": 0.7533468559837728,
                "recall": 0.795970852978997,
                "f1-score": 0.7740725302209254,
                "support": 2333
            },
            "1": {
                "precision": 0.7870246085011185,
                "recall": 0.7431347697507393,
                "f1-score": 0.7644502390265102,
                "support": 2367
            },
            "accuracy": 0.7693617021276595,
            "macro avg": {
                "precision": 0.7701857322424457,
                "recall": 0.7695528113648682,
                "f1-score": 0.7692613846237177,
                "support": 4700
            },
            "weighted avg": {
                "precision": 0.7703075453898488,
                "recall": 0.7693617021276595,
                "f1-score": 0.769226580591738,
                "support": 4700
            },
            "cross-entropy": 0.4797142111525372,
            "roc-auc": 0.8521077879856457,
            "score": 0.7693617021276595
        }
    }
}