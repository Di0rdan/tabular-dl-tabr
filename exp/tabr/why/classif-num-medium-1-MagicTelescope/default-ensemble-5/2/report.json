{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8457750640141816,
                "recall": 0.9188957842927455,
                "f1-score": 0.8808205128205128,
                "support": 4673
            },
            "1": {
                "precision": 0.9115725618292114,
                "recall": 0.8330490405117271,
                "f1-score": 0.8705436720142603,
                "support": 4690
            },
            "accuracy": 0.8758944782655131,
            "macro avg": {
                "precision": 0.8786738129216964,
                "recall": 0.8759724124022363,
                "f1-score": 0.8756820924173865,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8787335457777711,
                "recall": 0.8758944782655131,
                "f1-score": 0.8756727628064869,
                "support": 9363
            },
            "cross-entropy": 0.2869614812172527,
            "roc-auc": 0.9481123927000685,
            "score": 0.8758944782655131
        },
        "val": {
            "0": {
                "precision": 0.8538812785388128,
                "recall": 0.9004815409309791,
                "f1-score": 0.8765624999999999,
                "support": 623
            },
            "1": {
                "precision": 0.8864468864468864,
                "recall": 0.8344827586206897,
                "f1-score": 0.8596802841918294,
                "support": 580
            },
            "accuracy": 0.8686616791354946,
            "macro avg": {
                "precision": 0.8701640824928496,
                "recall": 0.8674821497758344,
                "f1-score": 0.8681213920959147,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8695820703814419,
                "recall": 0.8686616791354946,
                "f1-score": 0.8684231108323035,
                "support": 1203
            },
            "cross-entropy": 0.3080796680591822,
            "roc-auc": 0.9408147451154036,
            "score": 0.8686616791354946
        },
        "test": {
            "0": {
                "precision": 0.8393207054212932,
                "recall": 0.923132183908046,
                "f1-score": 0.8792336640437906,
                "support": 1392
            },
            "1": {
                "precision": 0.9163408913213448,
                "recall": 0.8265162200282088,
                "f1-score": 0.8691138301816835,
                "support": 1418
            },
            "accuracy": 0.8743772241992882,
            "macro avg": {
                "precision": 0.8778307983713189,
                "recall": 0.8748242019681274,
                "f1-score": 0.8741737471127371,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8781871195160523,
                "recall": 0.8743772241992882,
                "f1-score": 0.8741269293760084,
                "support": 2810
            },
            "cross-entropy": 0.29369441827920606,
            "roc-auc": 0.9466465638830796,
            "score": 0.8743772241992882
        }
    }
}