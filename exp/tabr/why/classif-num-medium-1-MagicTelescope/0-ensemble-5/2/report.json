{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8665870171246516,
                "recall": 0.9313075112347529,
                "f1-score": 0.8977823620422899,
                "support": 4673
            },
            "1": {
                "precision": 0.9260539046302695,
                "recall": 0.8571428571428571,
                "f1-score": 0.8902668585981619,
                "support": 4690
            },
            "accuracy": 0.8941578553882302,
            "macro avg": {
                "precision": 0.8963204608774605,
                "recall": 0.8942251841888049,
                "f1-score": 0.8940246103202258,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8963744466238878,
                "recall": 0.8941578553882302,
                "f1-score": 0.8940177875305994,
                "support": 9363
            },
            "cross-entropy": 0.25128747131376566,
            "roc-auc": 0.960042789932822,
            "score": 0.8941578553882302
        },
        "val": {
            "0": {
                "precision": 0.8635658914728682,
                "recall": 0.8940609951845907,
                "f1-score": 0.8785488958990536,
                "support": 623
            },
            "1": {
                "precision": 0.8817204301075269,
                "recall": 0.8482758620689655,
                "f1-score": 0.8646748681898067,
                "support": 580
            },
            "accuracy": 0.8719866999168745,
            "macro avg": {
                "precision": 0.8726431607901975,
                "recall": 0.8711684286267781,
                "f1-score": 0.8716118820444301,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8723187031171759,
                "recall": 0.8719866999168745,
                "f1-score": 0.8718598384831241,
                "support": 1203
            },
            "cross-entropy": 0.29389938326227183,
            "roc-auc": 0.9455194553606021,
            "score": 0.8719866999168745
        },
        "test": {
            "0": {
                "precision": 0.8428665351742275,
                "recall": 0.9209770114942529,
                "f1-score": 0.8801922416752489,
                "support": 1392
            },
            "1": {
                "precision": 0.9146625290923196,
                "recall": 0.8314527503526093,
                "f1-score": 0.8710749907646841,
                "support": 1418
            },
            "accuracy": 0.8758007117437723,
            "macro avg": {
                "precision": 0.8787645321332735,
                "recall": 0.8762148809234311,
                "f1-score": 0.8756336162199665,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8790966844183039,
                "recall": 0.8758007117437723,
                "f1-score": 0.8755914367673553,
                "support": 2810
            },
            "cross-entropy": 0.28299455177715654,
            "roc-auc": 0.9500399218585347,
            "score": 0.8758007117437723
        }
    }
}