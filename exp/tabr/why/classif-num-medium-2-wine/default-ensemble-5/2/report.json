{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-num-medium-2-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8875878220140515,
                "recall": 0.8320526893523601,
                "f1-score": 0.8589235127478754,
                "support": 911
            },
            "1": {
                "precision": 0.8360128617363344,
                "recall": 0.8904109589041096,
                "f1-score": 0.8623548922056384,
                "support": 876
            },
            "accuracy": 0.8606603245663123,
            "macro avg": {
                "precision": 0.8618003418751929,
                "recall": 0.8612318241282348,
                "f1-score": 0.8606392024767568,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.8623054128348236,
                "recall": 0.8606603245663123,
                "f1-score": 0.8606055991524644,
                "support": 1787
            },
            "cross-entropy": 0.3173293429778865,
            "roc-auc": 0.9410490253572521,
            "score": 0.8606603245663123
        },
        "val": {
            "0": {
                "precision": 0.8617021276595744,
                "recall": 0.7714285714285715,
                "f1-score": 0.8140703517587939,
                "support": 105
            },
            "1": {
                "precision": 0.8235294117647058,
                "recall": 0.896,
                "f1-score": 0.8582375478927202,
                "support": 125
            },
            "accuracy": 0.8391304347826087,
            "macro avg": {
                "precision": 0.8426157697121401,
                "recall": 0.8337142857142857,
                "f1-score": 0.8361539498257571,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8409560864123633,
                "recall": 0.8391304347826087,
                "f1-score": 0.8380742627011452,
                "support": 230
            },
            "cross-entropy": 0.37983674648426236,
            "roc-auc": 0.9097142857142857,
            "score": 0.8391304347826087
        },
        "test": {
            "0": {
                "precision": 0.7898832684824902,
                "recall": 0.7777777777777778,
                "f1-score": 0.7837837837837839,
                "support": 261
            },
            "1": {
                "precision": 0.7928571428571428,
                "recall": 0.8043478260869565,
                "f1-score": 0.7985611510791367,
                "support": 276
            },
            "accuracy": 0.7914338919925512,
            "macro avg": {
                "precision": 0.7913702056698165,
                "recall": 0.7910628019323671,
                "f1-score": 0.7911724674314603,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.7914117402281218,
                "recall": 0.7914338919925512,
                "f1-score": 0.791378855242848,
                "support": 537
            },
            "cross-entropy": 0.419526014784458,
            "roc-auc": 0.8897912155033594,
            "score": 0.7914338919925512
        }
    }
}