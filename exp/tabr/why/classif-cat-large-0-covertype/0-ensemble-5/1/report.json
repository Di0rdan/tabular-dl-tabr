{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/classif-cat-large-0-covertype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.962149306675266,
                "recall": 0.9585173881615935,
                "f1-score": 0.9603299134982901,
                "support": 24902
            },
            "1": {
                "precision": 0.9589949190219117,
                "recall": 0.9625866602916567,
                "f1-score": 0.9607874328892424,
                "support": 25098
            },
            "accuracy": 0.96056,
            "macro avg": {
                "precision": 0.9605721128485889,
                "recall": 0.9605520242266251,
                "f1-score": 0.9605586731937663,
                "support": 50000
            },
            "weighted avg": {
                "precision": 0.9605659302487882,
                "recall": 0.96056,
                "f1-score": 0.9605595699317724,
                "support": 50000
            },
            "cross-entropy": 0.09629287689630994,
            "roc-auc": 0.9943862737372365,
            "score": 0.96056
        },
        "val": {
            "0": {
                "precision": 0.9560104354806341,
                "recall": 0.9516941026050824,
                "f1-score": 0.9538473860200629,
                "support": 25028
            },
            "1": {
                "precision": 0.9518038668527008,
                "recall": 0.9561108441454429,
                "f1-score": 0.9539524941566614,
                "support": 24972
            },
            "accuracy": 0.9539,
            "macro avg": {
                "precision": 0.9539071511666675,
                "recall": 0.9539024733752626,
                "f1-score": 0.9538999400883621,
                "support": 50000
            },
            "weighted avg": {
                "precision": 0.9539095068450991,
                "recall": 0.9539,
                "f1-score": 0.9538998812278058,
                "support": 50000
            },
            "cross-entropy": 0.12154819919891299,
            "roc-auc": 0.9910036783150141,
            "score": 0.9539
        },
        "test": {
            "0": {
                "precision": 0.9543918247246411,
                "recall": 0.9532168387609213,
                "f1-score": 0.9538039698782014,
                "support": 25180
            },
            "1": {
                "precision": 0.9525974809866806,
                "recall": 0.9537872683319903,
                "f1-score": 0.9531920033822552,
                "support": 24820
            },
            "accuracy": 0.9535,
            "macro avg": {
                "precision": 0.9534946528556609,
                "recall": 0.9535020535464558,
                "f1-score": 0.9534979866302282,
                "support": 50000
            },
            "weighted avg": {
                "precision": 0.9535011124931175,
                "recall": 0.9535,
                "f1-score": 0.9535001897096136,
                "support": 50000
            },
            "cross-entropy": 0.11975100861422505,
            "roc-auc": 0.991183399747443,
            "score": 0.9535
        }
    }
}