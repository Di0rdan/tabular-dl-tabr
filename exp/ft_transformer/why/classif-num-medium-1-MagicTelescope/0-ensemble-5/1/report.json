{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.ft_transformer.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8678725914274479,
                "recall": 0.9445752193451744,
                "f1-score": 0.9046008812378318,
                "support": 4673
            },
            "1": {
                "precision": 0.939443535188216,
                "recall": 0.8567164179104477,
                "f1-score": 0.896174863387978,
                "support": 4690
            },
            "accuracy": 0.9005660578874293,
            "macro avg": {
                "precision": 0.9036580633078319,
                "recall": 0.900645818627811,
                "f1-score": 0.9003878723129048,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.9037230374637613,
                "recall": 0.9005660578874293,
                "f1-score": 0.9003802229321805,
                "support": 9363
            },
            "cross-entropy": 0.24773966669390746,
            "roc-auc": 0.964097475996253,
            "score": 0.9005660578874293
        },
        "val": {
            "0": {
                "precision": 0.8509687034277198,
                "recall": 0.9165329052969502,
                "f1-score": 0.8825347758887171,
                "support": 623
            },
            "1": {
                "precision": 0.9022556390977443,
                "recall": 0.8275862068965517,
                "f1-score": 0.8633093525179857,
                "support": 580
            },
            "accuracy": 0.8736492103075644,
            "macro avg": {
                "precision": 0.876612171262732,
                "recall": 0.872059556096751,
                "f1-score": 0.8729220642033514,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8756955718305578,
                "recall": 0.8736492103075644,
                "f1-score": 0.8732656607141333,
                "support": 1203
            },
            "cross-entropy": 0.3104232778388617,
            "roc-auc": 0.9377456135495654,
            "score": 0.8736492103075644
        },
        "test": {
            "0": {
                "precision": 0.8357142857142857,
                "recall": 0.9245689655172413,
                "f1-score": 0.8778990450204639,
                "support": 1392
            },
            "1": {
                "precision": 0.9173228346456693,
                "recall": 0.8215796897038082,
                "f1-score": 0.8668154761904763,
                "support": 1418
            },
            "accuracy": 0.8725978647686833,
            "macro avg": {
                "precision": 0.8765185601799775,
                "recall": 0.8730743276105248,
                "f1-score": 0.8723572606054701,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8768961086269911,
                "recall": 0.8725978647686833,
                "f1-score": 0.8723059843083919,
                "support": 2810
            },
            "cross-entropy": 0.3012209833876889,
            "roc-auc": 0.9426938945900815,
            "score": 0.8725978647686833
        }
    }
}
