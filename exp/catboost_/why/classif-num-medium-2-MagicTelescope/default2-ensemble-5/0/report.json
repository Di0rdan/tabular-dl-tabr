{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.catboost_.main",
    "data": ":data/classif-num-medium-2-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8907037709215567,
                "recall": 0.9466352336048007,
                "f1-score": 0.9178181818181818,
                "support": 4666
            },
            "1": {
                "precision": 0.9434604904632152,
                "recall": 0.884607196082606,
                "f1-score": 0.9130864740138447,
                "support": 4697
            },
            "accuracy": 0.9155185303855602,
            "macro avg": {
                "precision": 0.917082130692386,
                "recall": 0.9156212148437033,
                "f1-score": 0.9154523279160132,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.9171694669257403,
                "recall": 0.9155185303855602,
                "f1-score": 0.9154444947993875,
                "support": 9363
            },
            "cross-entropy": 0.22807614190228315,
            "roc-auc": 0.9750536612137448,
            "score": 0.9155185303855602
        },
        "val": {
            "0": {
                "precision": 0.8428571428571429,
                "recall": 0.885,
                "f1-score": 0.8634146341463415,
                "support": 600
            },
            "1": {
                "precision": 0.8795811518324608,
                "recall": 0.835820895522388,
                "f1-score": 0.8571428571428571,
                "support": 603
            },
            "accuracy": 0.8603491271820449,
            "macro avg": {
                "precision": 0.8612191473448019,
                "recall": 0.860410447761194,
                "f1-score": 0.8602787456445993,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8612649378796838,
                "recall": 0.8603491271820449,
                "f1-score": 0.8602709254737718,
                "support": 1203
            },
            "cross-entropy": 0.3348912636470915,
            "roc-auc": 0.930121614151465,
            "score": 0.8603491271820449
        },
        "test": {
            "0": {
                "precision": 0.8355987055016181,
                "recall": 0.9078762306610408,
                "f1-score": 0.8702392989551736,
                "support": 1422
            },
            "1": {
                "precision": 0.8964426877470356,
                "recall": 0.8170028818443804,
                "f1-score": 0.8548812664907652,
                "support": 1388
            },
            "accuracy": 0.8629893238434164,
            "macro avg": {
                "precision": 0.8660206966243269,
                "recall": 0.8624395562527106,
                "f1-score": 0.8625602827229695,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8656526013580734,
                "recall": 0.8629893238434164,
                "f1-score": 0.8626531960866332,
                "support": 2810
            },
            "cross-entropy": 0.30916511916339695,
            "roc-auc": 0.9401130647665139,
            "score": 0.8629893238434164
        }
    }
}
