{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.catboost_.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8657462985194078,
                "recall": 0.9259576289321635,
                "f1-score": 0.894840244028539,
                "support": 4673
            },
            "1": {
                "precision": 0.9207331042382588,
                "recall": 0.8569296375266524,
                "f1-score": 0.8876863611264495,
                "support": 4690
            },
            "accuracy": 0.8913809676385773,
            "macro avg": {
                "precision": 0.8932397013788334,
                "recall": 0.891443633229408,
                "f1-score": 0.8912633025774943,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8932896199784927,
                "recall": 0.8913809676385773,
                "f1-score": 0.8912568080773695,
                "support": 9363
            },
            "cross-entropy": 0.2690640972292547,
            "roc-auc": 0.9590516130180317,
            "score": 0.8913809676385773
        },
        "val": {
            "0": {
                "precision": 0.8651162790697674,
                "recall": 0.8956661316211878,
                "f1-score": 0.8801261829652995,
                "support": 623
            },
            "1": {
                "precision": 0.8835125448028673,
                "recall": 0.85,
                "f1-score": 0.8664323374340948,
                "support": 580
            },
            "accuracy": 0.8736492103075644,
            "macro avg": {
                "precision": 0.8743144119363173,
                "recall": 0.8728330658105938,
                "f1-score": 0.8732792601996971,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8739856341198073,
                "recall": 0.8736492103075644,
                "f1-score": 0.8735239964249015,
                "support": 1203
            },
            "cross-entropy": 0.3256090408974718,
            "roc-auc": 0.9329246692865445,
            "score": 0.8736492103075644
        },
        "test": {
            "0": {
                "precision": 0.8370860927152318,
                "recall": 0.9080459770114943,
                "f1-score": 0.8711233631977946,
                "support": 1392
            },
            "1": {
                "precision": 0.9015384615384615,
                "recall": 0.8265162200282088,
                "f1-score": 0.8623988226637234,
                "support": 1418
            },
            "accuracy": 0.8669039145907473,
            "macro avg": {
                "precision": 0.8693122771268467,
                "recall": 0.8672810985198516,
                "f1-score": 0.866761092930759,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8696104553456018,
                "recall": 0.8669039145907473,
                "f1-score": 0.8667207302877187,
                "support": 2810
            },
            "cross-entropy": 0.3138136656179338,
            "roc-auc": 0.9383252881669181,
            "score": 0.8669039145907473
        }
    }
}
