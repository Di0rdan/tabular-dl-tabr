{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.catboost_.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8924190629398753,
                "recall": 0.9497111063556601,
                "f1-score": 0.9201741654571842,
                "support": 4673
            },
            "1": {
                "precision": 0.9464692482915718,
                "recall": 0.8859275053304904,
                "f1-score": 0.9151982378854624,
                "support": 4690
            },
            "accuracy": 0.9177614012602798,
            "macro avg": {
                "precision": 0.9194441556157236,
                "recall": 0.9178193058430753,
                "f1-score": 0.9176862016713233,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.9194932239245445,
                "recall": 0.9177614012602798,
                "f1-score": 0.9176816843815274,
                "support": 9363
            },
            "cross-entropy": 0.2231861788048535,
            "roc-auc": 0.9763821289748258,
            "score": 0.9177614012602798
        },
        "val": {
            "0": {
                "precision": 0.864696734059098,
                "recall": 0.8924558587479936,
                "f1-score": 0.8783570300157979,
                "support": 623
            },
            "1": {
                "precision": 0.8803571428571428,
                "recall": 0.85,
                "f1-score": 0.8649122807017544,
                "support": 580
            },
            "accuracy": 0.8719866999168745,
            "macro avg": {
                "precision": 0.8725269384581205,
                "recall": 0.8712279293739968,
                "f1-score": 0.8716346553587762,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8722470558403664,
                "recall": 0.8719866999168745,
                "f1-score": 0.8718749397397005,
                "support": 1203
            },
            "cross-entropy": 0.317751087420525,
            "roc-auc": 0.9356450987989152,
            "score": 0.8719866999168745
        },
        "test": {
            "0": {
                "precision": 0.8367617783676178,
                "recall": 0.9058908045977011,
                "f1-score": 0.8699551569506727,
                "support": 1392
            },
            "1": {
                "precision": 0.8994627782041443,
                "recall": 0.8265162200282088,
                "f1-score": 0.8614479970599044,
                "support": 1418
            },
            "accuracy": 0.8658362989323843,
            "macro avg": {
                "precision": 0.868112278285881,
                "recall": 0.866203512312955,
                "f1-score": 0.8657015770052885,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8684023540858365,
                "recall": 0.8658362989323843,
                "f1-score": 0.8656622200378223,
                "support": 2810
            },
            "cross-entropy": 0.30525094167025674,
            "roc-auc": 0.941203917611011,
            "score": 0.8658362989323843
        }
    }
}
