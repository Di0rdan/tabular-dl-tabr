{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.catboost_.main",
    "data": ":data/classif-num-medium-0-bank-marketing",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9062167906482466,
                "recall": 0.9139871382636656,
                "f1-score": 0.91008537886873,
                "support": 3732
            },
            "1": {
                "precision": 0.9118131868131868,
                "recall": 0.9038671023965141,
                "f1-score": 0.9078227571115973,
                "support": 3672
            },
            "accuracy": 0.9089681253376554,
            "macro avg": {
                "precision": 0.9090149887307166,
                "recall": 0.9089271203300899,
                "f1-score": 0.9089540679901636,
                "support": 7404
            },
            "weighted avg": {
                "precision": 0.9089923128953644,
                "recall": 0.9089681253376554,
                "f1-score": 0.9089632358254842,
                "support": 7404
            },
            "cross-entropy": 0.25706320824948037,
            "roc-auc": 0.9700614511018173,
            "score": 0.9089681253376554
        },
        "val": {
            "0": {
                "precision": 0.8299319727891157,
                "recall": 0.8026315789473685,
                "f1-score": 0.8160535117056855,
                "support": 456
            },
            "1": {
                "precision": 0.8238747553816047,
                "recall": 0.8487903225806451,
                "f1-score": 0.8361469712015889,
                "support": 496
            },
            "accuracy": 0.8266806722689075,
            "macro avg": {
                "precision": 0.8269033640853602,
                "recall": 0.8257109507640068,
                "f1-score": 0.8261002414536371,
                "support": 952
            },
            "weighted avg": {
                "precision": 0.8267761116188158,
                "recall": 0.8266806722689075,
                "f1-score": 0.826522372955652,
                "support": 952
            },
            "cross-entropy": 0.4177629430249218,
            "roc-auc": 0.8893649193548387,
            "score": 0.8266806722689075
        },
        "test": {
            "0": {
                "precision": 0.7948028673835126,
                "recall": 0.8056312443233424,
                "f1-score": 0.8001804239963916,
                "support": 1101
            },
            "1": {
                "precision": 0.8065099457504521,
                "recall": 0.7957181088314005,
                "f1-score": 0.8010776829815895,
                "support": 1121
            },
            "accuracy": 0.8006300630063007,
            "macro avg": {
                "precision": 0.8006564065669823,
                "recall": 0.8006746765773715,
                "f1-score": 0.8006290534889906,
                "support": 2222
            },
            "weighted avg": {
                "precision": 0.8007090936883456,
                "recall": 0.8006300630063007,
                "f1-score": 0.8006330915582308,
                "support": 2222
            },
            "cross-entropy": 0.4295829747889448,
            "roc-auc": 0.884415351869722,
            "score": 0.8006300630063007
        }
    }
}
