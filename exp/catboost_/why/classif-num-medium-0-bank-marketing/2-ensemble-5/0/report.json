{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.catboost_.main",
    "data": ":data/classif-num-medium-0-bank-marketing",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8689581095596133,
                "recall": 0.8670953912111469,
                "f1-score": 0.8680257510729615,
                "support": 3732
            },
            "1": {
                "precision": 0.8652173913043478,
                "recall": 0.8671023965141612,
                "f1-score": 0.8661588683351469,
                "support": 3672
            },
            "accuracy": 0.86709886547812,
            "macro avg": {
                "precision": 0.8670877504319805,
                "recall": 0.867098893862654,
                "f1-score": 0.8670923097040542,
                "support": 7404
            },
            "weighted avg": {
                "precision": 0.8671029073130797,
                "recall": 0.86709886547812,
                "f1-score": 0.8670998740587454,
                "support": 7404
            },
            "cross-entropy": 0.3227407709873339,
            "roc-auc": 0.9426973510614203,
            "score": 0.86709886547812
        },
        "val": {
            "0": {
                "precision": 0.8264840182648402,
                "recall": 0.793859649122807,
                "f1-score": 0.8098434004474273,
                "support": 456
            },
            "1": {
                "precision": 0.8171206225680934,
                "recall": 0.8467741935483871,
                "f1-score": 0.8316831683168316,
                "support": 496
            },
            "accuracy": 0.8214285714285714,
            "macro avg": {
                "precision": 0.8218023204164668,
                "recall": 0.8203169213355971,
                "f1-score": 0.8207632843821295,
                "support": 952
            },
            "weighted avg": {
                "precision": 0.8216056104228376,
                "recall": 0.8214285714285714,
                "f1-score": 0.8212221030348481,
                "support": 952
            },
            "cross-entropy": 0.40774258850150735,
            "roc-auc": 0.8939763723825693,
            "score": 0.8214285714285714
        },
        "test": {
            "0": {
                "precision": 0.7959001782531194,
                "recall": 0.8110808356039964,
                "f1-score": 0.8034188034188035,
                "support": 1101
            },
            "1": {
                "precision": 0.8109090909090909,
                "recall": 0.7957181088314005,
                "f1-score": 0.8032417829806393,
                "support": 1121
            },
            "accuracy": 0.8033303330333034,
            "macro avg": {
                "precision": 0.8034046345811052,
                "recall": 0.8033994722176985,
                "f1-score": 0.8033302931997214,
                "support": 2222
            },
            "weighted avg": {
                "precision": 0.8034721814427431,
                "recall": 0.8033303330333034,
                "f1-score": 0.8033294965280826,
                "support": 2222
            },
            "cross-entropy": 0.42382061157782547,
            "roc-auc": 0.8867779757434042,
            "score": 0.8033303330333034
        }
    }
}
