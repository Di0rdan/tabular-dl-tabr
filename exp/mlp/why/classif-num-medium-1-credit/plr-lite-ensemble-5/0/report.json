{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_function": "bin.ffn.main",
    "data": ":data/classif-num-medium-1-credit",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7933333333333333,
                "recall": 0.8260610868702896,
                "f1-score": 0.8093664982510689,
                "support": 5042
            },
            "1": {
                "precision": 0.8153684210526316,
                "recall": 0.7811617587736991,
                "f1-score": 0.7978986402966626,
                "support": 4958
            },
            "accuracy": 0.8038,
            "macro avg": {
                "precision": 0.8043508771929825,
                "recall": 0.8036114228219944,
                "f1-score": 0.8036325692738657,
                "support": 10000
            },
            "weighted avg": {
                "precision": 0.8042583298245614,
                "recall": 0.8038,
                "f1-score": 0.8036807342772743,
                "support": 10000
            },
            "cross-entropy": 0.4289934987331799,
            "roc-auc": 0.8833767310621436,
            "score": 0.8038
        },
        "val": {
            "0": {
                "precision": 0.7572362278244631,
                "recall": 0.8005923000987167,
                "f1-score": 0.7783109404990403,
                "support": 1013
            },
            "1": {
                "precision": 0.7857900318133616,
                "recall": 0.7402597402597403,
                "f1-score": 0.7623456790123457,
                "support": 1001
            },
            "accuracy": 0.7706057596822244,
            "macro avg": {
                "precision": 0.7715131298189124,
                "recall": 0.7704260201792286,
                "f1-score": 0.770328309755693,
                "support": 2014
            },
            "weighted avg": {
                "precision": 0.7714280638685977,
                "recall": 0.7706057596822244,
                "f1-score": 0.7703758726002412,
                "support": 2014
            },
            "cross-entropy": 0.4846753840585116,
            "roc-auc": 0.8478165467306632,
            "score": 0.7706057596822244
        },
        "test": {
            "0": {
                "precision": 0.7610508757297748,
                "recall": 0.7927888792354474,
                "f1-score": 0.7765957446808509,
                "support": 2302
            },
            "1": {
                "precision": 0.7927888792354474,
                "recall": 0.7610508757297748,
                "f1-score": 0.7765957446808509,
                "support": 2398
            },
            "accuracy": 0.776595744680851,
            "macro avg": {
                "precision": 0.7769198774826112,
                "recall": 0.7769198774826112,
                "f1-score": 0.7765957446808509,
                "support": 4700
            },
            "weighted avg": {
                "precision": 0.7772440102843712,
                "recall": 0.776595744680851,
                "f1-score": 0.7765957446808509,
                "support": 4700
            },
            "cross-entropy": 0.4827065125460293,
            "roc-auc": 0.852597987462764,
            "score": 0.776595744680851
        }
    }
}
