seed = 13
batch_size = 256
patience = 16
n_epochs = inf

[data]
seed = 0
cache = true
path = ":data/regression-num-medium-1-elevators"
num_policy = "quantile"
cat_policy = "__null__"
y_policy = "standard"

[optimizer]
type = "AdamW"
lr = 0.00042393836966418734
weight_decay = 1.0856663323257014e-06

[model]
num_embeddings = "__null__"

[model.backbone]
type = "MLP"
n_blocks = 2
d_layer = 527
dropout = 0.4142623130124406
activation = "ReLU"
