{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-1-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9474885844748858,
                "recall": 0.9253065774804905,
                "f1-score": 0.9362662154540328,
                "support": 897
            },
            "1": {
                "precision": 0.9264544456641054,
                "recall": 0.9483146067415731,
                "f1-score": 0.9372570794003331,
                "support": 890
            },
            "accuracy": 0.9367655288192501,
            "macro avg": {
                "precision": 0.9369715150694956,
                "recall": 0.9368105921110318,
                "f1-score": 0.9367616474271829,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9370127123195447,
                "recall": 0.9367655288192501,
                "f1-score": 0.9367597067311494,
                "support": 1787
            },
            "cross-entropy": 0.2708136386579714,
            "roc-auc": 0.9869239537534604,
            "score": 0.9367655288192501
        },
        "val": {
            "0": {
                "precision": 0.7575757575757576,
                "recall": 0.8264462809917356,
                "f1-score": 0.7905138339920948,
                "support": 121
            },
            "1": {
                "precision": 0.7857142857142857,
                "recall": 0.7064220183486238,
                "f1-score": 0.7439613526570049,
                "support": 109
            },
            "accuracy": 0.7695652173913043,
            "macro avg": {
                "precision": 0.7716450216450217,
                "recall": 0.7664341496701796,
                "f1-score": 0.7672375933245499,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.7709109730848861,
                "recall": 0.7695652173913043,
                "f1-score": 0.7684520058811175,
                "support": 230
            },
            "cross-entropy": 0.4742458647952396,
            "roc-auc": 0.8575327924785806,
            "score": 0.7695652173913043
        },
        "test": {
            "0": {
                "precision": 0.7974683544303798,
                "recall": 0.7297297297297297,
                "f1-score": 0.7620967741935484,
                "support": 259
            },
            "1": {
                "precision": 0.7666666666666667,
                "recall": 0.8273381294964028,
                "f1-score": 0.7958477508650519,
                "support": 278
            },
            "accuracy": 0.7802607076350093,
            "macro avg": {
                "precision": 0.7820675105485233,
                "recall": 0.7785339296130662,
                "f1-score": 0.7789722625293001,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.7815226017333365,
                "recall": 0.7802607076350093,
                "f1-score": 0.77956934684658,
                "support": 537
            },
            "cross-entropy": 0.48151829308288036,
            "roc-auc": 0.8413377406183162,
            "score": 0.7802607076350093
        }
    }
}
