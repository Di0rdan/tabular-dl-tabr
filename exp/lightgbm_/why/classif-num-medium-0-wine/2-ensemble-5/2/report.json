{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-0-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9921171171171171,
                "recall": 0.9832589285714286,
                "f1-score": 0.9876681614349776,
                "support": 896
            },
            "1": {
                "precision": 0.9833147942157954,
                "recall": 0.9921436588103255,
                "f1-score": 0.987709497206704,
                "support": 891
            },
            "accuracy": 0.9876888640179071,
            "macro avg": {
                "precision": 0.9877159556664563,
                "recall": 0.9877012936908771,
                "f1-score": 0.9876888293208408,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9877282700521604,
                "recall": 0.9876888640179071,
                "f1-score": 0.9876887714923969,
                "support": 1787
            },
            "cross-entropy": 0.2351805493221401,
            "roc-auc": 0.9994375801667469,
            "score": 0.9876888640179071
        },
        "val": {
            "0": {
                "precision": 0.8240740740740741,
                "recall": 0.8165137614678899,
                "f1-score": 0.8202764976958524,
                "support": 109
            },
            "1": {
                "precision": 0.8360655737704918,
                "recall": 0.8429752066115702,
                "f1-score": 0.8395061728395061,
                "support": 121
            },
            "accuracy": 0.8304347826086956,
            "macro avg": {
                "precision": 0.830069823922283,
                "recall": 0.8297444840397301,
                "f1-score": 0.8298913352676793,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8303826456534938,
                "recall": 0.8304347826086956,
                "f1-score": 0.8303929789670789,
                "support": 230
            },
            "cross-entropy": 0.41320071734207997,
            "roc-auc": 0.9031010690727121,
            "score": 0.8304347826086956
        },
        "test": {
            "0": {
                "precision": 0.8433734939759037,
                "recall": 0.7720588235294118,
                "f1-score": 0.8061420345489443,
                "support": 272
            },
            "1": {
                "precision": 0.7847222222222222,
                "recall": 0.8528301886792453,
                "f1-score": 0.8173598553345389,
                "support": 265
            },
            "accuracy": 0.8119180633147114,
            "macro avg": {
                "precision": 0.8140478580990629,
                "recall": 0.8124445061043286,
                "f1-score": 0.8117509449417416,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.8144301289577927,
                "recall": 0.8119180633147114,
                "f1-score": 0.8116778306535674,
                "support": 537
            },
            "cross-entropy": 0.4281340810193079,
            "roc-auc": 0.8941315205327414,
            "score": 0.8119180633147114
        }
    }
}
