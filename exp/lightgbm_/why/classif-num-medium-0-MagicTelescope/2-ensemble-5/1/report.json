{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-0-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8842251840063656,
                "recall": 0.9429359355112431,
                "f1-score": 0.912637306231393,
                "support": 4714
            },
            "1": {
                "precision": 0.9379612546125461,
                "recall": 0.8748117874811787,
                "f1-score": 0.9052865887590428,
                "support": 4649
            },
            "accuracy": 0.9091103278863613,
            "macro avg": {
                "precision": 0.9110932193094559,
                "recall": 0.9088738614962109,
                "f1-score": 0.908961947495218,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.91090669551423,
                "recall": 0.9091103278863613,
                "f1-score": 0.9089874626418432,
                "support": 9363
            },
            "cross-entropy": 0.23625408758171862,
            "roc-auc": 0.970693283704882,
            "score": 0.9091103278863613
        },
        "val": {
            "0": {
                "precision": 0.8360128617363344,
                "recall": 0.8950086058519794,
                "f1-score": 0.8645054031587698,
                "support": 581
            },
            "1": {
                "precision": 0.8950086058519794,
                "recall": 0.8360128617363344,
                "f1-score": 0.8645054031587698,
                "support": 622
            },
            "accuracy": 0.8645054031587698,
            "macro avg": {
                "precision": 0.8655107337941569,
                "recall": 0.8655107337941569,
                "f1-score": 0.8645054031587698,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8665160644295441,
                "recall": 0.8645054031587698,
                "f1-score": 0.8645054031587698,
                "support": 1203
            },
            "cross-entropy": 0.3197685541454309,
            "roc-auc": 0.9350022967386311,
            "score": 0.8645054031587698
        },
        "test": {
            "0": {
                "precision": 0.8181818181818182,
                "recall": 0.8786791098348887,
                "f1-score": 0.8473520249221183,
                "support": 1393
            },
            "1": {
                "precision": 0.8713850837138508,
                "recall": 0.808045165843331,
                "f1-score": 0.8385206883925302,
                "support": 1417
            },
            "accuracy": 0.8430604982206406,
            "macro avg": {
                "precision": 0.8447834509478345,
                "recall": 0.8433621378391098,
                "f1-score": 0.8429363566573242,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8450106535052667,
                "recall": 0.8430604982206406,
                "f1-score": 0.8428986427646712,
                "support": 2810
            },
            "cross-entropy": 0.35262202529958847,
            "roc-auc": 0.9202555777171977,
            "score": 0.8430604982206406
        }
    }
}
