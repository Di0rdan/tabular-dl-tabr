{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-0-bank-marketing",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8638090070537168,
                "recall": 0.8531618435155413,
                "f1-score": 0.8584524130493394,
                "support": 3732
            },
            "1": {
                "precision": 0.8526089295320065,
                "recall": 0.8632897603485838,
                "f1-score": 0.857916102841678,
                "support": 3672
            },
            "accuracy": 0.8581847649918962,
            "macro avg": {
                "precision": 0.8582089682928616,
                "recall": 0.8582258019320625,
                "f1-score": 0.8581842579455087,
                "support": 7404
            },
            "weighted avg": {
                "precision": 0.8582543494821717,
                "recall": 0.8581847649918962,
                "f1-score": 0.8581864310014554,
                "support": 7404
            },
            "cross-entropy": 0.33243077200842647,
            "roc-auc": 0.9381856440325327,
            "score": 0.8581847649918962
        },
        "val": {
            "0": {
                "precision": 0.8204545454545454,
                "recall": 0.7916666666666666,
                "f1-score": 0.8058035714285715,
                "support": 456
            },
            "1": {
                "precision": 0.814453125,
                "recall": 0.8407258064516129,
                "f1-score": 0.8273809523809523,
                "support": 496
            },
            "accuracy": 0.8172268907563025,
            "macro avg": {
                "precision": 0.8174538352272727,
                "recall": 0.8161962365591398,
                "f1-score": 0.8165922619047619,
                "support": 952
            },
            "weighted avg": {
                "precision": 0.8173277549656226,
                "recall": 0.8172268907563025,
                "f1-score": 0.8170455682272909,
                "support": 952
            },
            "cross-entropy": 0.410409914494132,
            "roc-auc": 0.8917657045840408,
            "score": 0.8172268907563025
        },
        "test": {
            "0": {
                "precision": 0.7969723953695459,
                "recall": 0.812897366030881,
                "f1-score": 0.8048561151079138,
                "support": 1101
            },
            "1": {
                "precision": 0.8125568698817106,
                "recall": 0.7966101694915254,
                "f1-score": 0.8045045045045044,
                "support": 1121
            },
            "accuracy": 0.8046804680468047,
            "macro avg": {
                "precision": 0.8047646326256283,
                "recall": 0.8047537677612032,
                "f1-score": 0.8046803098062091,
                "support": 2222
            },
            "weighted avg": {
                "precision": 0.804834769774648,
                "recall": 0.8046804680468047,
                "f1-score": 0.8046787274002531,
                "support": 2222
            },
            "cross-entropy": 0.425650027530782,
            "roc-auc": 0.8851891192906296,
            "score": 0.8046804680468047
        }
    }
}
