{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-4-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9455388180764774,
                "recall": 0.9076751946607341,
                "f1-score": 0.9262202043132802,
                "support": 899
            },
            "1": {
                "precision": 0.9101731601731602,
                "recall": 0.9470720720720721,
                "f1-score": 0.9282560706401767,
                "support": 888
            },
            "accuracy": 0.9272523782876329,
            "macro avg": {
                "precision": 0.9278559891248188,
                "recall": 0.9273736333664031,
                "f1-score": 0.9272381374767285,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9279648369807048,
                "recall": 0.9272523782876329,
                "f1-score": 0.9272318715199305,
                "support": 1787
            },
            "cross-entropy": 0.2859614980345817,
            "roc-auc": 0.9825356502219683,
            "score": 0.9272523782876329
        },
        "val": {
            "0": {
                "precision": 0.8878504672897196,
                "recall": 0.7851239669421488,
                "f1-score": 0.8333333333333334,
                "support": 121
            },
            "1": {
                "precision": 0.7886178861788617,
                "recall": 0.8899082568807339,
                "f1-score": 0.8362068965517241,
                "support": 109
            },
            "accuracy": 0.8347826086956521,
            "macro avg": {
                "precision": 0.8382341767342907,
                "recall": 0.8375161119114414,
                "f1-score": 0.8347701149425287,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8408228527632695,
                "recall": 0.8347826086956521,
                "f1-score": 0.8346951524237882,
                "support": 230
            },
            "cross-entropy": 0.44936270612348334,
            "roc-auc": 0.8760330578512397,
            "score": 0.8347826086956521
        },
        "test": {
            "0": {
                "precision": 0.811965811965812,
                "recall": 0.7392996108949417,
                "f1-score": 0.7739307535641547,
                "support": 257
            },
            "1": {
                "precision": 0.7788778877887789,
                "recall": 0.8428571428571429,
                "f1-score": 0.8096054888507719,
                "support": 280
            },
            "accuracy": 0.7932960893854749,
            "macro avg": {
                "precision": 0.7954218498772954,
                "recall": 0.7910783768760423,
                "f1-score": 0.7917681212074633,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.7947132630466887,
                "recall": 0.7932960893854749,
                "f1-score": 0.7925321052964691,
                "support": 537
            },
            "cross-entropy": 0.4592484680995825,
            "roc-auc": 0.8623123957754307,
            "score": 0.7932960893854749
        }
    }
}
