{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8653922739944245,
                "recall": 0.9300235394821313,
                "f1-score": 0.896544610624033,
                "support": 4673
            },
            "1": {
                "precision": 0.9246717346233587,
                "recall": 0.855863539445629,
                "f1-score": 0.8889381020927914,
                "support": 4690
            },
            "accuracy": 0.8928762148883904,
            "macro avg": {
                "precision": 0.8950320043088916,
                "recall": 0.8929435394638802,
                "f1-score": 0.8927413563584122,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8950858199038232,
                "recall": 0.8928762148883904,
                "f1-score": 0.8927344509517566,
                "support": 9363
            },
            "cross-entropy": 0.2684057723812088,
            "roc-auc": 0.9594465233065511,
            "score": 0.8928762148883904
        },
        "val": {
            "0": {
                "precision": 0.8609375,
                "recall": 0.884430176565008,
                "f1-score": 0.8725257323832147,
                "support": 623
            },
            "1": {
                "precision": 0.872113676731794,
                "recall": 0.846551724137931,
                "f1-score": 0.8591426071741032,
                "support": 580
            },
            "accuracy": 0.8661679135494597,
            "macro avg": {
                "precision": 0.866525588365897,
                "recall": 0.8654909503514695,
                "f1-score": 0.8658341697786589,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8663258478839905,
                "recall": 0.8661679135494597,
                "f1-score": 0.8660733528143996,
                "support": 1203
            },
            "cross-entropy": 0.3311902020263859,
            "roc-auc": 0.9305446393977971,
            "score": 0.8661679135494597
        },
        "test": {
            "0": {
                "precision": 0.8256041802743305,
                "recall": 0.9080459770114943,
                "f1-score": 0.8648648648648649,
                "support": 1392
            },
            "1": {
                "precision": 0.8999218139171228,
                "recall": 0.811706629055007,
                "f1-score": 0.853540971449759,
                "support": 1418
            },
            "accuracy": 0.8594306049822064,
            "macro avg": {
                "precision": 0.8627629970957267,
                "recall": 0.8598763030332506,
                "f1-score": 0.859202918157312,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8631068153296613,
                "recall": 0.8594306049822064,
                "f1-score": 0.8591505300383097,
                "support": 2810
            },
            "cross-entropy": 0.3210119805614098,
            "roc-auc": 0.9349871520516188,
            "score": 0.8594306049822064
        }
    }
}
