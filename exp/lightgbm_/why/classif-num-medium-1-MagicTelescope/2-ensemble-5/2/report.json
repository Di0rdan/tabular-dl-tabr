{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-1-MagicTelescope",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8568592416120707,
                "recall": 0.9236036807190242,
                "f1-score": 0.8889804325437692,
                "support": 4673
            },
            "1": {
                "precision": 0.9174757281553398,
                "recall": 0.8462686567164179,
                "f1-score": 0.8804347826086958,
                "support": 4690
            },
            "accuracy": 0.8848659617643918,
            "macro avg": {
                "precision": 0.8871674848837052,
                "recall": 0.8849361687177211,
                "f1-score": 0.8847076075762326,
                "support": 9363
            },
            "weighted avg": {
                "precision": 0.8872225142691178,
                "recall": 0.8848659617643918,
                "f1-score": 0.8846998495900691,
                "support": 9363
            },
            "cross-entropy": 0.281600756959633,
            "roc-auc": 0.954162664711355,
            "score": 0.8848659617643918
        },
        "val": {
            "0": {
                "precision": 0.858034321372855,
                "recall": 0.8828250401284109,
                "f1-score": 0.870253164556962,
                "support": 623
            },
            "1": {
                "precision": 0.8701067615658363,
                "recall": 0.843103448275862,
                "f1-score": 0.8563922942206654,
                "support": 580
            },
            "accuracy": 0.8636741479634248,
            "macro avg": {
                "precision": 0.8640705414693457,
                "recall": 0.8629642442021365,
                "f1-score": 0.8633227293888137,
                "support": 1203
            },
            "weighted avg": {
                "precision": 0.8638547829787812,
                "recall": 0.8636741479634248,
                "f1-score": 0.8635704506791133,
                "support": 1203
            },
            "cross-entropy": 0.3332256931745833,
            "roc-auc": 0.9302291470637074,
            "score": 0.8636741479634248
        },
        "test": {
            "0": {
                "precision": 0.8284217419777341,
                "recall": 0.9087643678160919,
                "f1-score": 0.8667351832819459,
                "support": 1392
            },
            "1": {
                "precision": 0.9010132501948558,
                "recall": 0.8152327221438646,
                "f1-score": 0.855979266938171,
                "support": 1418
            },
            "accuracy": 0.8615658362989324,
            "macro avg": {
                "precision": 0.8647174960862949,
                "recall": 0.8619985449799783,
                "f1-score": 0.8613572251100584,
                "support": 2810
            },
            "weighted avg": {
                "precision": 0.8650533286865877,
                "recall": 0.8615658362989324,
                "f1-score": 0.8613074646429876,
                "support": 2810
            },
            "cross-entropy": 0.3237773465405223,
            "roc-auc": 0.9340235559230259,
            "score": 0.8615658362989324
        }
    }
}
