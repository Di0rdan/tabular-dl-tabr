{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-3-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9865470852017937,
                "recall": 0.97669256381798,
                "f1-score": 0.9815950920245398,
                "support": 901
            },
            "1": {
                "precision": 0.976536312849162,
                "recall": 0.9864559819413092,
                "f1-score": 0.9814710836608647,
                "support": 886
            },
            "accuracy": 0.9815332960268607,
            "macro avg": {
                "precision": 0.9815416990254778,
                "recall": 0.9815742728796446,
                "f1-score": 0.9815330878427022,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9815837140185638,
                "recall": 0.9815332960268607,
                "f1-score": 0.9815336083030982,
                "support": 1787
            },
            "cross-entropy": 0.16622672162715824,
            "roc-auc": 0.9988024342153065,
            "score": 0.9815332960268607
        },
        "val": {
            "0": {
                "precision": 0.8317757009345794,
                "recall": 0.7876106194690266,
                "f1-score": 0.8090909090909091,
                "support": 113
            },
            "1": {
                "precision": 0.8048780487804879,
                "recall": 0.8461538461538461,
                "f1-score": 0.8250000000000001,
                "support": 117
            },
            "accuracy": 0.8173913043478261,
            "macro avg": {
                "precision": 0.8183268748575336,
                "recall": 0.8168822328114363,
                "f1-score": 0.8170454545454546,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8180929822301067,
                "recall": 0.8173913043478261,
                "f1-score": 0.8171837944664031,
                "support": 230
            },
            "cross-entropy": 0.4425269714729514,
            "roc-auc": 0.8706603131381893,
            "score": 0.8173913043478261
        },
        "test": {
            "0": {
                "precision": 0.8151260504201681,
                "recall": 0.7376425855513308,
                "f1-score": 0.7744510978043911,
                "support": 263
            },
            "1": {
                "precision": 0.7692307692307693,
                "recall": 0.8394160583941606,
                "f1-score": 0.8027923211169286,
                "support": 274
            },
            "accuracy": 0.7895716945996276,
            "macro avg": {
                "precision": 0.7921784098254687,
                "recall": 0.7885293219727456,
                "f1-score": 0.7886217094606598,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.7917083464240875,
                "recall": 0.7895716945996276,
                "f1-score": 0.7889119826975667,
                "support": 537
            },
            "cross-entropy": 0.45219294960498446,
            "roc-auc": 0.8705559101884488,
            "score": 0.7895716945996276
        }
    }
}
