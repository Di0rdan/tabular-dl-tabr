{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/classif-num-medium-3-wine",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9944258639910813,
                "recall": 0.9900110987791343,
                "f1-score": 0.9922135706340378,
                "support": 901
            },
            "1": {
                "precision": 0.9898876404494382,
                "recall": 0.9943566591422122,
                "f1-score": 0.992117117117117,
                "support": 886
            },
            "accuracy": 0.9921656407386682,
            "macro avg": {
                "precision": 0.9921567522202598,
                "recall": 0.9921838789606732,
                "f1-score": 0.9921653438755774,
                "support": 1787
            },
            "weighted avg": {
                "precision": 0.9921757990454206,
                "recall": 0.9921656407386682,
                "f1-score": 0.9921657486888829,
                "support": 1787
            },
            "cross-entropy": 0.1419398351479881,
            "roc-auc": 0.9996154260503127,
            "score": 0.9921656407386682
        },
        "val": {
            "0": {
                "precision": 0.8301886792452831,
                "recall": 0.7787610619469026,
                "f1-score": 0.8036529680365297,
                "support": 113
            },
            "1": {
                "precision": 0.7983870967741935,
                "recall": 0.8461538461538461,
                "f1-score": 0.8215767634854771,
                "support": 117
            },
            "accuracy": 0.8130434782608695,
            "macro avg": {
                "precision": 0.8142878880097383,
                "recall": 0.8124574540503744,
                "f1-score": 0.8126148657610035,
                "support": 230
            },
            "weighted avg": {
                "precision": 0.8140113525099898,
                "recall": 0.8130434782608695,
                "f1-score": 0.8127707248518637,
                "support": 230
            },
            "cross-entropy": 0.44243655628432427,
            "roc-auc": 0.8718705090386506,
            "score": 0.8130434782608695
        },
        "test": {
            "0": {
                "precision": 0.8208333333333333,
                "recall": 0.7490494296577946,
                "f1-score": 0.7833001988071571,
                "support": 263
            },
            "1": {
                "precision": 0.7777777777777778,
                "recall": 0.843065693430657,
                "f1-score": 0.809106830122592,
                "support": 274
            },
            "accuracy": 0.7970204841713222,
            "macro avg": {
                "precision": 0.7993055555555555,
                "recall": 0.7960575615442258,
                "f1-score": 0.7962035144648745,
                "support": 537
            },
            "weighted avg": {
                "precision": 0.7988645768673702,
                "recall": 0.7970204841713222,
                "f1-score": 0.7964678281934312,
                "support": 537
            },
            "cross-entropy": 0.45230396964206643,
            "roc-auc": 0.8717215730898392,
            "score": 0.7970204841713222
        }
    }
}
